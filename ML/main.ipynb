{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d78de89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting jsonlines\n",
      "  Downloading jsonlines-3.0.0-py3-none-any.whl (8.5 kB)\n",
      "Requirement already satisfied: attrs>=19.2.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from jsonlines) (20.3.0)\n",
      "Requirement already satisfied: typing-extensions in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from jsonlines) (4.0.1)\n",
      "Installing collected packages: jsonlines\n",
      "Successfully installed jsonlines-3.0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install jsonlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06d7ff72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import csv, jsonlines\n",
    "import numpy as np\n",
    "import copy\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd5aa3f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib is building the font cache; this may take a moment.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b89f2463",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  ml-latest-small.zip\n",
      "   creating: ml-latest-small/\n",
      "  inflating: ml-latest-small/links.csv  \n",
      "  inflating: ml-latest-small/tags.csv  \n",
      "  inflating: ml-latest-small/ratings.csv  \n",
      "  inflating: ml-latest-small/README.txt  \n",
      "  inflating: ml-latest-small/movies.csv  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\r",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r",
      " 48  955k   48  459k    0     0   298k      0  0:00:03  0:00:01  0:00:02  298k\r",
      "100  955k  100  955k    0     0   560k      0  0:00:01  0:00:01 --:--:--  560k\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "curl -o ml-latest-small.zip http://files.grouplens.org/datasets/movielens/ml-latest-small.zip\n",
    "unzip ml-latest-small.zip\n",
    "rm ml-latest-small.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1b239c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## some utility functions\n",
    "\n",
    "\n",
    "def load_csv_data(filename, delimiter, verbose=True):\n",
    "    \"\"\"\n",
    "    input: a file readable as csv and separated by a delimiter\n",
    "    and has format users - movies - ratings - etc\n",
    "    output: a list, where each row of the list is of the form\n",
    "    {'in0':userID, 'in1':movieID, 'label':rating}\n",
    "    \"\"\"\n",
    "    to_data_list = list()\n",
    "    users = list()\n",
    "    movies = list()\n",
    "    ratings = list()\n",
    "    unique_users = set()\n",
    "    unique_movies = set()\n",
    "    with open(filename, \"r\") as csvfile:\n",
    "        reader = csv.reader(csvfile, delimiter=delimiter)\n",
    "        header = next(reader)\n",
    "        for count, row in enumerate(reader):\n",
    "            # if count!=0:\n",
    "            to_data_list.append(\n",
    "                {\"in0\": [int(row[0])], \"in1\": [int(row[1])], \"label\": float(row[2])}\n",
    "            )\n",
    "            users.append(row[0])\n",
    "            movies.append(row[1])\n",
    "            ratings.append(float(row[2]))\n",
    "            unique_users.add(row[0])\n",
    "            unique_movies.add(row[1])\n",
    "    if verbose:\n",
    "        print(\"In file {}, there are {} ratings\".format(filename, len(ratings)))\n",
    "        print(\n",
    "            \"The ratings have mean: {}, median: {}, and variance: {}\".format(\n",
    "                round(np.mean(ratings), 2), round(np.median(ratings), 2), round(np.var(ratings), 2)\n",
    "            )\n",
    "        )\n",
    "        print(\n",
    "            \"There are {} unique users and {} unique movies\".format(\n",
    "                len(unique_users), len(unique_movies)\n",
    "            )\n",
    "        )\n",
    "    return to_data_list\n",
    "\n",
    "\n",
    "def csv_to_augmented_data_dict(filename, delimiter):\n",
    "    \"\"\"\n",
    "    Input: a file that must be readable as csv and separated by delimiter (to make columns)\n",
    "    has format users - movies - ratings - etc\n",
    "    Output:\n",
    "      Users dictionary: keys as user ID's; each key corresponds to a list of movie ratings by that user\n",
    "      Movies dictionary: keys as movie ID's; each key corresponds a list of ratings of that movie by different users\n",
    "    \"\"\"\n",
    "    to_users_dict = dict()\n",
    "    to_movies_dict = dict()\n",
    "    with open(filename, \"r\") as csvfile:\n",
    "        reader = csv.reader(csvfile, delimiter=delimiter)\n",
    "        header = next(reader)\n",
    "        for count, row in enumerate(reader):\n",
    "            # if count!=0:\n",
    "            if row[0] not in to_users_dict:\n",
    "                to_users_dict[row[0]] = [(row[1], row[2])]\n",
    "            else:\n",
    "                to_users_dict[row[0]].append((row[1], row[2]))\n",
    "            if row[1] not in to_movies_dict:\n",
    "                to_movies_dict[row[1]] = list(row[0])\n",
    "            else:\n",
    "                to_movies_dict[row[1]].append(row[0])\n",
    "    return to_users_dict, to_movies_dict\n",
    "\n",
    "\n",
    "def user_dict_to_data_list(user_dict):\n",
    "    # turn user_dict format to data list format (acceptable to the algorithm)\n",
    "    data_list = list()\n",
    "    for user, movie_rating_list in user_dict.items():\n",
    "        for movie, rating in movie_rating_list:\n",
    "            data_list.append({\"in0\": [int(user)], \"in1\": [int(movie)], \"label\": float(rating)})\n",
    "    return data_list\n",
    "\n",
    "\n",
    "def divide_user_dicts(user_dict, sp_ratio_dict):\n",
    "    \"\"\"\n",
    "    Input: A user dictionary, a ration dictionary\n",
    "         - format of sp_ratio_dict = {'train':0.8, \"test\":0.2}\n",
    "    Output:\n",
    "        A dictionary of dictionaries, with key corresponding to key provided by sp_ratio_dict\n",
    "        and each key corresponds to a subdivded user dictionary\n",
    "    \"\"\"\n",
    "    ratios = [val for _, val in sp_ratio_dict.items()]\n",
    "    assert np.sum(ratios) == 1, \"the sampling ratios must sum to 1!\"\n",
    "    divided_dict = {}\n",
    "    for user, movie_rating_list in user_dict.items():\n",
    "        sub_movies_ptr = 0\n",
    "        sub_movies_list = []\n",
    "        # movie_list, _ = zip(*movie_rating_list)\n",
    "        # print(movie_list)\n",
    "        for i, ratio in enumerate(ratios):\n",
    "            if i < len(ratios) - 1:\n",
    "                sub_movies_ptr_end = sub_movies_ptr + int(len(movie_rating_list) * ratio)\n",
    "                sub_movies_list.append(movie_rating_list[sub_movies_ptr:sub_movies_ptr_end])\n",
    "                sub_movies_ptr = sub_movies_ptr_end\n",
    "            else:\n",
    "                sub_movies_list.append(movie_rating_list[sub_movies_ptr:])\n",
    "        for subset_name in sp_ratio_dict.keys():\n",
    "            if subset_name not in divided_dict:\n",
    "                divided_dict[subset_name] = {user: sub_movies_list.pop(0)}\n",
    "            else:\n",
    "                # access sub-dictionary\n",
    "                divided_dict[subset_name][user] = sub_movies_list.pop(0)\n",
    "\n",
    "    return divided_dict\n",
    "\n",
    "\n",
    "def write_csv_to_jsonl(jsonl_fname, csv_fname, csv_delimiter):\n",
    "    \"\"\"\n",
    "    Input: a file readable as csv and separated by delimiter (to make columns)\n",
    "        - has format users - movies - ratings - etc\n",
    "    Output: a jsonline file converted from the csv file\n",
    "    \"\"\"\n",
    "    with jsonlines.open(jsonl_fname, mode=\"w\") as writer:\n",
    "        with open(csv_fname, \"r\") as csvfile:\n",
    "            reader = csv.reader(csvfile, delimiter=csv_delimiter)\n",
    "            header = next(reader)\n",
    "            for count, row in enumerate(reader):\n",
    "                # print(row)\n",
    "                # if count!=0:\n",
    "                writer.write({\"in0\": [int(row[0])], \"in1\": [int(row[1])], \"label\": float(row[2])})\n",
    "        print(\"Created {} jsonline file\".format(jsonl_fname))\n",
    "\n",
    "\n",
    "def write_data_list_to_jsonl(data_list, to_fname):\n",
    "    \"\"\"\n",
    "    Input: a data list, where each row of the list is a Python dictionary taking form\n",
    "    {'in0':userID, 'in1':movieID, 'label':rating}\n",
    "    Output: save the list as a jsonline file\n",
    "    \"\"\"\n",
    "    with jsonlines.open(to_fname, mode=\"w\") as writer:\n",
    "        for row in data_list:\n",
    "            # print(row)\n",
    "            writer.write({\"in0\": row[\"in0\"], \"in1\": row[\"in1\"], \"label\": row[\"label\"]})\n",
    "    print(\"Created {} jsonline file\".format(to_fname))\n",
    "\n",
    "\n",
    "def data_list_to_inference_format(data_list, binarize=True, label_thres=3):\n",
    "    \"\"\"\n",
    "    Input: a data list\n",
    "    Output: test data and label, acceptable by SageMaker for inference\n",
    "    \"\"\"\n",
    "    data_ = [({\"in0\": row[\"in0\"], \"in1\": row[\"in1\"]}, row[\"label\"]) for row in data_list]\n",
    "    data, label = zip(*data_)\n",
    "    infer_data = {\"instances\": data}\n",
    "    if binarize:\n",
    "        label = get_binarized_label(list(label), label_thres)\n",
    "    return infer_data, label\n",
    "\n",
    "\n",
    "def get_binarized_label(data_list, thres):\n",
    "    \"\"\"\n",
    "    Input: data list\n",
    "    Output: a binarized data list for recommendation task\n",
    "    \"\"\"\n",
    "    for i, row in enumerate(data_list):\n",
    "        if type(row) is dict:\n",
    "            # if i < 10:\n",
    "            # print(row['label'])\n",
    "            if row[\"label\"] > thres:\n",
    "                # print(row)\n",
    "                data_list[i][\"label\"] = 1\n",
    "            else:\n",
    "                data_list[i][\"label\"] = 0\n",
    "        else:\n",
    "            if row > thres:\n",
    "                data_list[i] = 1\n",
    "            else:\n",
    "                data_list[i] = 0\n",
    "    return data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4664bba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In file ml-latest-small/ratings.csv, there are 100836 ratings\n",
      "The ratings have mean: 3.5, median: 3.5, and variance: 1.09\n",
      "There are 610 unique users and 9724 unique movies\n"
     ]
    }
   ],
   "source": [
    "## Load data and shuffle\n",
    "prefix = \"ml-latest-small\"\n",
    "rating_data_path = os.path.join(prefix, \"ratings.csv\")\n",
    "\n",
    "\n",
    "rating_data_list = load_csv_data(train_path, \",\")\n",
    "random.shuffle(train_data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "250cfc79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_data_list, validation_data_list = train_test_split(rating_data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f7a9aef6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created train_r.jsonl jsonline file\n",
      "Created validation_r.jsonl jsonline file\n"
     ]
    }
   ],
   "source": [
    "## Save training and validation data locally for rating-prediction (regression) task\n",
    "\n",
    "write_data_list_to_jsonl(copy.deepcopy(train_data_list), \"train_r.jsonl\")\n",
    "write_data_list_to_jsonl(copy.deepcopy(validation_data_list), \"validation_r.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "714a0a27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created train_c.jsonl jsonline file\n",
      "Created validation_c.jsonl jsonline file\n"
     ]
    }
   ],
   "source": [
    "## Save training and validation data locally for recommendation (classification) task\n",
    "\n",
    "### binarize the data\n",
    "\n",
    "train_c = get_binarized_label(copy.deepcopy(train_data_list), 3.0)\n",
    "valid_c = get_binarized_label(copy.deepcopy(validation_data_list), 3.0)\n",
    "\n",
    "write_data_list_to_jsonl(train_c, \"train_c.jsonl\")\n",
    "write_data_list_to_jsonl(valid_c, \"validation_c.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "38d072cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 0.6127441257751861 fraction of positive ratings in train_c.jsonl\n",
      "There are 0.6099408941251141 fraction of positive ratings in validation_c.jsonl\n"
     ]
    }
   ],
   "source": [
    "train_c_label = [row[\"label\"] for row in train_c]\n",
    "valid_c_label = [row[\"label\"] for row in valid_c]\n",
    "\n",
    "print(\n",
    "    \"There are {} fraction of positive ratings in train_c.jsonl\".format(\n",
    "        np.count_nonzero(train_c_label) / len(train_c_label)\n",
    "    )\n",
    ")\n",
    "print(\n",
    "    \"There are {} fraction of positive ratings in validation_c.jsonl\".format(\n",
    "        np.sum(valid_c_label) / len(valid_c_label)\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "90800c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mse_loss(res, labels):\n",
    "    if type(res) is dict:\n",
    "        res = res[\"predictions\"]\n",
    "    assert len(res) == len(labels), \"result and label length mismatch!\"\n",
    "    loss = 0\n",
    "    for row, label in zip(res, labels):\n",
    "        if type(row) is dict:\n",
    "            loss += (row[\"scores\"][0] - label) ** 2\n",
    "        else:\n",
    "            loss += (row - label) ** 2\n",
    "    return round(loss / float(len(labels)), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c90d47f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_r_data, valid_r_label = data_list_to_inference_format(\n",
    "    copy.deepcopy(validation_data_list), binarize=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c80019b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Baseline 1 (global rating average) prediction is 3.5\n",
      "The validation mse loss of the Baseline 1 is 1.1\n"
     ]
    }
   ],
   "source": [
    "train_r_label = [row[\"label\"] for row in copy.deepcopy(train_data_list)]\n",
    "\n",
    "bs1_prediction = round(np.mean(train_r_label), 2)\n",
    "print(\"The Baseline 1 (global rating average) prediction is {}\".format(bs1_prediction))\n",
    "print(\n",
    "    \"The validation mse loss of the Baseline 1 is {}\".format(\n",
    "        get_mse_loss(len(valid_r_label) * [bs1_prediction], valid_r_label)\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "10c501b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bs2_predictor(test_data, user_dict, is_classification=False, thres=3):\n",
    "    test_data = copy.deepcopy(test_data[\"instances\"])\n",
    "    predictions = list()\n",
    "    for row in test_data:\n",
    "        userID = str(row[\"in0\"][0])\n",
    "        # predict movie ID based on local average of user's prediction\n",
    "        local_movies, local_ratings = zip(*user_dict[userID])\n",
    "        local_ratings = [float(score) for score in local_ratings]\n",
    "        predictions.append(np.mean(local_ratings))\n",
    "        if is_classification:\n",
    "            predictions[-1] = int(predictions[-1] > 3)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "46cb575f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The validation loss of the Baseline 2 (user-based rating average) is 0.89\n"
     ]
    }
   ],
   "source": [
    "bs2_prediction = bs2_predictor(valid_r_data, to_users_dict, is_classification=False)\n",
    "print(\n",
    "    \"The validation loss of the Baseline 2 (user-based rating average) is {}\".format(\n",
    "        get_mse_loss(bs2_prediction, valid_r_label)\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e8e1a569",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import os\n",
    "import sagemaker\n",
    "\n",
    "bucket = sagemaker.session.Session().default_bucket()\n",
    "input_prefix = \"object2vec/movielens/input\"\n",
    "output_prefix = \"object2vec/movielens/output\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b0950f18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded train data to s3://sagemaker-ap-northeast-1-073956268323/object2vec/movielens/input/rating/train/train_r.jsonl and defined input path\n",
      "Uploaded validation data to s3://sagemaker-ap-northeast-1-073956268323/object2vec/movielens/input/rating/validation/validation_r.jsonl and defined input path\n",
      "Trained model will be saved at s3://sagemaker-ap-northeast-1-073956268323/object2vec/movielens/output\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.inputs import TrainingInput\n",
    "\n",
    "s3_client = boto3.client(\"s3\")\n",
    "input_paths = {}\n",
    "output_path = os.path.join(\"s3://\", bucket, output_prefix)\n",
    "\n",
    "for data_name in [\"train\", \"validation\"]:\n",
    "    pre_key = os.path.join(input_prefix, \"rating\", f\"{data_name}\")\n",
    "    fname = \"{}_r.jsonl\".format(data_name)\n",
    "    data_path = os.path.join(\"s3://\", bucket, pre_key, fname)\n",
    "    s3_client.upload_file(fname, bucket, os.path.join(pre_key, fname))\n",
    "    input_paths[data_name] = TrainingInput(\n",
    "        data_path, distribution=\"ShardedByS3Key\", content_type=\"application/jsonlines\"\n",
    "    )\n",
    "    print(\"Uploaded {} data to {} and defined input path\".format(data_name, data_path))\n",
    "\n",
    "print(\"Trained model will be saved at\", output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "01897c0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arn:aws:iam::073956268323:role/service-role/AmazonSageMaker-ExecutionRole-20220425T161571\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "\n",
    "role = get_execution_role()\n",
    "print(role)\n",
    "\n",
    "## Get docker image of ObjectToVec algorithm\n",
    "from sagemaker import image_uris\n",
    "\n",
    "container = image_uris.retrieve(region=boto3.Session().region_name, framework=\"object2vec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "26ab5745",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded data to s3://sagemaker-ap-northeast-1-073956268323/object2vec/movielens/input/recommendation/train/train_c.jsonl\n",
      "Uploaded data to s3://sagemaker-ap-northeast-1-073956268323/object2vec/movielens/input/recommendation/validation/validation_c.jsonl\n"
     ]
    }
   ],
   "source": [
    "for data_name in [\"train\", \"validation\"]:\n",
    "    fname = \"{}_c.jsonl\".format(data_name)\n",
    "    pre_key = os.path.join(input_prefix, \"recommendation\", f\"{data_name}\")\n",
    "    data_path = os.path.join(\"s3://\", bucket, pre_key, fname)\n",
    "    s3_client.upload_file(fname, bucket, os.path.join(pre_key, fname))\n",
    "    input_paths[data_name] = TrainingInput(\n",
    "        data_path, distribution=\"ShardedByS3Key\", content_type=\"application/jsonlines\"\n",
    "    )\n",
    "    print(\"Uploaded data to {}\".format(data_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0260ba8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.session import s3_input\n",
    "\n",
    "hyperparameters_c = {\n",
    "    \"_kvstore\": \"device\",\n",
    "    \"_num_gpus\": \"auto\",\n",
    "    \"_num_kv_servers\": \"auto\",\n",
    "    \"bucket_width\": 0,\n",
    "    \"early_stopping_patience\": 3,\n",
    "    \"early_stopping_tolerance\": 0.01,\n",
    "    \"enc0_cnn_filter_width\": 3,\n",
    "    \"enc0_layers\": \"auto\",\n",
    "    \"enc0_max_seq_len\": 1,\n",
    "    \"enc0_network\": \"pooled_embedding\",\n",
    "    \"enc0_token_embedding_dim\": 300,\n",
    "    \"enc0_vocab_size\": 611,\n",
    "    \"enc1_cnn_filter_width\": 3,\n",
    "    \"enc1_layers\": \"auto\",\n",
    "    \"enc1_max_seq_len\": 1,\n",
    "    \"enc1_network\": \"pooled_embedding\",\n",
    "    \"enc1_token_embedding_dim\": 300,\n",
    "    \"enc1_vocab_size\": 193610,\n",
    "    \"enc_dim\": 2048,\n",
    "    \"epochs\": 20,\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"mini_batch_size\": 2048,\n",
    "    \"mlp_activation\": \"relu\",\n",
    "    \"mlp_dim\": 1024,\n",
    "    \"mlp_layers\": 1,\n",
    "    \"num_classes\": 2,\n",
    "    \"optimizer\": \"adam\",\n",
    "    \"output_layer\": \"softmax\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "691780e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-04-25 13:37:53 Starting - Starting the training job...\n",
      "2022-04-25 13:38:16 Starting - Preparing the instances for trainingProfilerReport-1650893873: InProgress\n",
      "......\n",
      "2022-04-25 13:39:23 Downloading - Downloading input data...\n",
      "2022-04-25 13:39:38 Training - Downloading the training image........\u001b[34mDocker entrypoint called with argument(s): train\u001b[0m\n",
      "\u001b[34mRunning default environment configuration script\u001b[0m\n",
      "\u001b[34m[04/25/2022 13:41:05 INFO 140532052252480 integration.py:636] worker started\u001b[0m\n",
      "\u001b[34m[04/25/2022 13:41:05 INFO 140532052252480] Reading default configuration from /opt/amazon/lib/python3.7/site-packages/algorithm/default-input.json: {'enc_dim': 4096, 'mlp_dim': 512, 'mlp_activation': 'linear', 'mlp_layers': 2, 'output_layer': 'softmax', 'optimizer': 'adam', 'learning_rate': 0.0004, 'mini_batch_size': 32, 'epochs': 30, 'bucket_width': 0, 'early_stopping_tolerance': 0.01, 'early_stopping_patience': 3, 'dropout': 0, 'weight_decay': 0, 'negative_sampling_rate': 0, 'comparator_list': 'hadamard, concat, abs_diff', 'tied_token_embedding_weight': 'false', 'token_embedding_storage_type': 'dense', 'enc0_network': 'hcnn', 'enc1_network': 'enc0', 'enc0_token_embedding_dim': 300, 'enc0_layers': 'auto', 'enc0_cnn_filter_width': 3, 'enc1_token_embedding_dim': 300, 'enc1_layers': 'auto', 'enc1_cnn_filter_width': 3, 'enc0_pretrained_embedding_file': '', 'enc0_freeze_pretrained_embedding': 'true', 'enc1_pretrained_embedding_file': '', 'enc1_freeze_pretrained_embedding': 'true', 'enc0_vocab_file': '', 'enc1_vocab_file': '', 'num_classes': 2, '_num_gpus': 'auto', '_num_kv_servers': 'auto', '_tuning_objective_metric': '', '_kvstore': 'auto_gpu'}\u001b[0m\n",
      "\u001b[34m[04/25/2022 13:41:05 INFO 140532052252480] Merging with provided configuration from /opt/ml/input/config/hyperparameters.json: {'_kvstore': 'device', '_num_gpus': 'auto', '_num_kv_servers': 'auto', 'bucket_width': '0', 'early_stopping_patience': '3', 'early_stopping_tolerance': '0.01', 'enc0_cnn_filter_width': '3', 'enc0_layers': 'auto', 'enc0_max_seq_len': '1', 'enc0_network': 'pooled_embedding', 'enc0_token_embedding_dim': '300', 'enc0_vocab_size': '611', 'enc1_cnn_filter_width': '3', 'enc1_layers': 'auto', 'enc1_max_seq_len': '1', 'enc1_network': 'pooled_embedding', 'enc1_token_embedding_dim': '300', 'enc1_vocab_size': '193610', 'enc_dim': '2048', 'epochs': '20', 'learning_rate': '0.001', 'mini_batch_size': '2048', 'mlp_activation': 'relu', 'mlp_dim': '1024', 'mlp_layers': '1', 'num_classes': '2', 'optimizer': 'adam', 'output_layer': 'softmax'}\u001b[0m\n",
      "\u001b[34m[04/25/2022 13:41:05 INFO 140532052252480] Final configuration: {'enc_dim': '2048', 'mlp_dim': '1024', 'mlp_activation': 'relu', 'mlp_layers': '1', 'output_layer': 'softmax', 'optimizer': 'adam', 'learning_rate': '0.001', 'mini_batch_size': '2048', 'epochs': '20', 'bucket_width': '0', 'early_stopping_tolerance': '0.01', 'early_stopping_patience': '3', 'dropout': 0, 'weight_decay': 0, 'negative_sampling_rate': 0, 'comparator_list': 'hadamard, concat, abs_diff', 'tied_token_embedding_weight': 'false', 'token_embedding_storage_type': 'dense', 'enc0_network': 'pooled_embedding', 'enc1_network': 'pooled_embedding', 'enc0_token_embedding_dim': '300', 'enc0_layers': 'auto', 'enc0_cnn_filter_width': '3', 'enc1_token_embedding_dim': '300', 'enc1_layers': 'auto', 'enc1_cnn_filter_width': '3', 'enc0_pretrained_embedding_file': '', 'enc0_freeze_pretrained_embedding': 'true', 'enc1_pretrained_embedding_file': '', 'enc1_freeze_pretrained_embedding': 'true', 'enc0_vocab_file': '', 'enc1_vocab_file': '', 'num_classes': '2', '_num_gpus': 'auto', '_num_kv_servers': 'auto', '_tuning_objective_metric': '', '_kvstore': 'device', 'enc0_max_seq_len': '1', 'enc0_vocab_size': '611', 'enc1_max_seq_len': '1', 'enc1_vocab_size': '193610'}\u001b[0m\n",
      "\u001b[34mProcess 1 is a worker.\u001b[0m\n",
      "\u001b[34m[04/25/2022 13:41:05 INFO 140532052252480] Using default worker.\u001b[0m\n",
      "\u001b[34m[04/25/2022 13:41:05 INFO 140532052252480] Loaded iterator creator application/jsonlines for content type ('application/jsonlines', '1.0')\u001b[0m\n",
      "\u001b[34m[04/25/2022 13:41:05 INFO 140532052252480] Checkpoint loading and saving are disabled.\u001b[0m\n",
      "\u001b[34m[04/25/2022 13:41:05 INFO 140532052252480] create_iter params {'enc_dim': '2048', 'mlp_dim': '1024', 'mlp_activation': 'relu', 'mlp_layers': '1', 'output_layer': 'softmax', 'optimizer': 'adam', 'learning_rate': '0.001', 'mini_batch_size': '2048', 'epochs': '20', 'bucket_width': '0', 'early_stopping_tolerance': '0.01', 'early_stopping_patience': '3', 'dropout': 0, 'weight_decay': 0, 'negative_sampling_rate': 0, 'comparator_list': 'hadamard, concat, abs_diff', 'tied_token_embedding_weight': 'false', 'token_embedding_storage_type': 'dense', 'enc0_network': 'pooled_embedding', 'enc1_network': 'pooled_embedding', 'enc0_token_embedding_dim': '300', 'enc0_layers': 'auto', 'enc0_cnn_filter_width': '3', 'enc1_token_embedding_dim': '300', 'enc1_layers': 'auto', 'enc1_cnn_filter_width': '3', 'enc0_pretrained_embedding_file': '', 'enc0_freeze_pretrained_embedding': 'true', 'enc1_pretrained_embedding_file': '', 'enc1_freeze_pretrained_embedding': 'true', 'enc0_vocab_file': '', 'enc1_vocab_file': '', 'num_classes': '2', '_num_gpus': 'auto', '_num_kv_servers': 'auto', '_tuning_objective_metric': '', '_kvstore': 'device', 'enc0_max_seq_len': '1', 'enc0_vocab_size': '611', 'enc1_max_seq_len': '1', 'enc1_vocab_size': '193610'}\u001b[0m\n",
      "\u001b[34m[04/25/2022 13:41:05 INFO 140532052252480] create_iter content_params {}\u001b[0m\n",
      "\u001b[34m[04/25/2022 13:41:05 INFO 140532052252480] Parameters of encoders: [{'network': 'pooled_embedding', 'token_embedding_dim': '300', 'layers': 'auto', 'cnn_filter_width': '3', 'pretrained_embedding_file': '', 'freeze_pretrained_embedding': 'true', 'vocab_file': '', 'max_seq_len': '1', 'vocab_size': '611'}, {'network': 'pooled_embedding', 'token_embedding_dim': '300', 'layers': 'auto', 'cnn_filter_width': '3', 'pretrained_embedding_file': '', 'freeze_pretrained_embedding': 'true', 'vocab_file': '', 'max_seq_len': '1', 'vocab_size': '193610'}]\u001b[0m\n",
      "\u001b[34m[04/25/2022 13:41:05 INFO 140532052252480] Inconsistent enc_dim and token_embedding_dim found for token-embedding-encoder: 2048 vs 300. Setting token embedding dim to be 2048\u001b[0m\n",
      "\u001b[34m[04/25/2022 13:41:05 INFO 140532052252480] Inconsistent enc_dim and token_embedding_dim found for token-embedding-encoder: 2048 vs 300. Setting token embedding dim to be 2048\u001b[0m\n",
      "\u001b[34m[04/25/2022 13:41:05 INFO 140532052252480] Encoder configs: [{'num_layers': 1, 'enc_index': 0, 'token_embedding_dim': 2048, 'vocab_size': 611, 'vocab_file': '', 'vocab_dict': None, 'dropout': 0.0, 'pretrained_embedding_file': '', 'pretrained_embedding_file_path': None, 'freeze_pretrained_embedding': True, 'is_train': True}, {'num_layers': 1, 'enc_index': 1, 'token_embedding_dim': 2048, 'vocab_size': 193610, 'vocab_file': '', 'vocab_dict': None, 'dropout': 0.0, 'pretrained_embedding_file': '', 'pretrained_embedding_file_path': None, 'freeze_pretrained_embedding': True, 'is_train': True}]\u001b[0m\n",
      "\u001b[34m[04/25/2022 13:41:05 INFO 140532052252480] Config: {'enc_dim': 2048, 'max_seq_lens': [1, 1], 'dropout': 0.0, 'weight_decay': 0.0, 'mlp_activation': 'relu', 'mlp_dim': 1024, 'mlp_layers': 1, 'output_layer': 'softmax', 'learning_rate': 0.001, 'optimizer': 'adam', 'num_classes': 2, 'epochs': 20, 'mini_batch_size': 2048, 'bucket_width': 0, 'comparator_list': ['hadamard', 'concat', 'abs_diff'], 'tied_token_embedding_weight': False, 'negative_sampling_rate': 0, 'token_embedding_storage_type': 'dense', 'early_stopping_patience': 3, 'early_stopping_tolerance': 0.01, 'enc_configs': [{'num_layers': 1, 'enc_index': 0, 'token_embedding_dim': 2048, 'vocab_size': 611, 'vocab_file': '', 'vocab_dict': None, 'dropout': 0.0, 'pretrained_embedding_file': '', 'pretrained_embedding_file_path': None, 'freeze_pretrained_embedding': True, 'is_train': True}, {'num_layers': 1, 'enc_index': 1, 'token_embedding_dim': 2048, 'vocab_size': 193610, 'vocab_file': '', 'vocab_dict': None, 'dropout': 0.0, 'pretrained_embedding_file': '', 'pretrained_embedding_file_path': None, 'freeze_pretrained_embedding': True, 'is_train': True}]}\u001b[0m\n",
      "\u001b[34m[04/25/2022 13:41:05 INFO 140532052252480] use bucketing: False\u001b[0m\n",
      "\u001b[34m[04/25/2022 13:41:05 INFO 140532052252480] Creating data iterator for /opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34m[04/25/2022 13:41:07 INFO 140532052252480] Source words: 75627\u001b[0m\n",
      "\u001b[34m[04/25/2022 13:41:07 INFO 140532052252480] Target words: 75627\u001b[0m\n",
      "\u001b[34m[04/25/2022 13:41:07 INFO 140532052252480] Total: 75627 samples in 1 buckets\u001b[0m\n",
      "\u001b[34m[04/25/2022 13:41:07 INFO 140532052252480] Bucket of (1, 1) : 75627 samples in 37 batches of 2048, approx 2048.0 words/batch\u001b[0m\n",
      "\u001b[34m[04/25/2022 13:41:07 INFO 140532052252480] 0 sentence pairs discarded\u001b[0m\n",
      "\u001b[34m[04/25/2022 13:41:07 INFO 140532052252480] fill up mode: replicate\u001b[0m\n",
      "\u001b[34m[04/25/2022 13:41:07 INFO 140532052252480] \u001b[0m\n",
      "\u001b[34m[04/25/2022 13:41:07 INFO 140532052252480] Negative sampling not used\u001b[0m\n",
      "\u001b[34m[04/25/2022 13:41:07 INFO 140532052252480] Replicating 149 random sentences from bucket (1, 1) to size it to multiple of 2048\u001b[0m\n",
      "\u001b[34m[04/25/2022 13:41:07 INFO 140532052252480] Bucket batch sizes: [BucketBatchSize(batch_size=2048, average_words_per_batch=2048.0)]\u001b[0m\n",
      "\u001b[34m[04/25/2022 13:41:07 INFO 140532052252480] create_iter params {'enc_dim': '2048', 'mlp_dim': '1024', 'mlp_activation': 'relu', 'mlp_layers': '1', 'output_layer': 'softmax', 'optimizer': 'adam', 'learning_rate': '0.001', 'mini_batch_size': '2048', 'epochs': '20', 'bucket_width': '0', 'early_stopping_tolerance': '0.01', 'early_stopping_patience': '3', 'dropout': 0, 'weight_decay': 0, 'negative_sampling_rate': 0, 'comparator_list': 'hadamard, concat, abs_diff', 'tied_token_embedding_weight': 'false', 'token_embedding_storage_type': 'dense', 'enc0_network': 'pooled_embedding', 'enc1_network': 'pooled_embedding', 'enc0_token_embedding_dim': '300', 'enc0_layers': 'auto', 'enc0_cnn_filter_width': '3', 'enc1_token_embedding_dim': '300', 'enc1_layers': 'auto', 'enc1_cnn_filter_width': '3', 'enc0_pretrained_embedding_file': '', 'enc0_freeze_pretrained_embedding': 'true', 'enc1_pretrained_embedding_file': '', 'enc1_freeze_pretrained_embedding': 'true', 'enc0_vocab_file': '', 'enc1_vocab_file': '', 'num_classes': '2', '_num_gpus': 'auto', '_num_kv_servers': 'auto', '_tuning_objective_metric': '', '_kvstore': 'device', 'enc0_max_seq_len': '1', 'enc0_vocab_size': '611', 'enc1_max_seq_len': '1', 'enc1_vocab_size': '193610'}\u001b[0m\n",
      "\u001b[34m[04/25/2022 13:41:07 INFO 140532052252480] create_iter content_params {}\u001b[0m\n",
      "\u001b[34m[04/25/2022 13:41:07 INFO 140532052252480] Parameters of encoders: [{'network': 'pooled_embedding', 'token_embedding_dim': '300', 'layers': 'auto', 'cnn_filter_width': '3', 'pretrained_embedding_file': '', 'freeze_pretrained_embedding': 'true', 'vocab_file': '', 'max_seq_len': '1', 'vocab_size': '611'}, {'network': 'pooled_embedding', 'token_embedding_dim': '300', 'layers': 'auto', 'cnn_filter_width': '3', 'pretrained_embedding_file': '', 'freeze_pretrained_embedding': 'true', 'vocab_file': '', 'max_seq_len': '1', 'vocab_size': '193610'}]\u001b[0m\n",
      "\u001b[34m[04/25/2022 13:41:07 INFO 140532052252480] Inconsistent enc_dim and token_embedding_dim found for token-embedding-encoder: 2048 vs 300. Setting token embedding dim to be 2048\u001b[0m\n",
      "\u001b[34m[04/25/2022 13:41:07 INFO 140532052252480] Inconsistent enc_dim and token_embedding_dim found for token-embedding-encoder: 2048 vs 300. Setting token embedding dim to be 2048\u001b[0m\n",
      "\u001b[34m[04/25/2022 13:41:07 INFO 140532052252480] Encoder configs: [{'num_layers': 1, 'enc_index': 0, 'token_embedding_dim': 2048, 'vocab_size': 611, 'vocab_file': '', 'vocab_dict': None, 'dropout': 0.0, 'pretrained_embedding_file': '', 'pretrained_embedding_file_path': None, 'freeze_pretrained_embedding': True, 'is_train': True}, {'num_layers': 1, 'enc_index': 1, 'token_embedding_dim': 2048, 'vocab_size': 193610, 'vocab_file': '', 'vocab_dict': None, 'dropout': 0.0, 'pretrained_embedding_file': '', 'pretrained_embedding_file_path': None, 'freeze_pretrained_embedding': True, 'is_train': True}]\u001b[0m\n",
      "\u001b[34m[04/25/2022 13:41:07 INFO 140532052252480] Config: {'enc_dim': 2048, 'max_seq_lens': [1, 1], 'dropout': 0.0, 'weight_decay': 0.0, 'mlp_activation': 'relu', 'mlp_dim': 1024, 'mlp_layers': 1, 'output_layer': 'softmax', 'learning_rate': 0.001, 'optimizer': 'adam', 'num_classes': 2, 'epochs': 20, 'mini_batch_size': 2048, 'bucket_width': 0, 'comparator_list': ['hadamard', 'concat', 'abs_diff'], 'tied_token_embedding_weight': False, 'negative_sampling_rate': 0, 'token_embedding_storage_type': 'dense', 'early_stopping_patience': 3, 'early_stopping_tolerance': 0.01, 'enc_configs': [{'num_layers': 1, 'enc_index': 0, 'token_embedding_dim': 2048, 'vocab_size': 611, 'vocab_file': '', 'vocab_dict': None, 'dropout': 0.0, 'pretrained_embedding_file': '', 'pretrained_embedding_file_path': None, 'freeze_pretrained_embedding': True, 'is_train': True}, {'num_layers': 1, 'enc_index': 1, 'token_embedding_dim': 2048, 'vocab_size': 193610, 'vocab_file': '', 'vocab_dict': None, 'dropout': 0.0, 'pretrained_embedding_file': '', 'pretrained_embedding_file_path': None, 'freeze_pretrained_embedding': True, 'is_train': True}]}\u001b[0m\n",
      "\u001b[34m[04/25/2022 13:41:07 INFO 140532052252480] use bucketing: False\u001b[0m\n",
      "\u001b[34m[04/25/2022 13:41:07 INFO 140532052252480] Creating data iterator for /opt/ml/input/data/validation\u001b[0m\n",
      "\u001b[34m[04/25/2022 13:41:08 INFO 140532052252480] Source words: 25209\u001b[0m\n",
      "\u001b[34m[04/25/2022 13:41:08 INFO 140532052252480] Target words: 25209\u001b[0m\n",
      "\u001b[34m[04/25/2022 13:41:08 INFO 140532052252480] Total: 25209 samples in 1 buckets\u001b[0m\n",
      "\u001b[34m[04/25/2022 13:41:08 INFO 140532052252480] Bucket of (1, 1) : 25209 samples in 13 batches of 2048, approx 2048.0 words/batch\u001b[0m\n",
      "\u001b[34m[04/25/2022 13:41:08 INFO 140532052252480] 0 sentence pairs discarded\u001b[0m\n",
      "\u001b[34m[04/25/2022 13:41:08 INFO 140532052252480] fill up mode: replicate\u001b[0m\n",
      "\u001b[34m[04/25/2022 13:41:08 INFO 140532052252480] \u001b[0m\n",
      "\u001b[34m[04/25/2022 13:41:08 INFO 140532052252480] Negative sampling not used\u001b[0m\n",
      "\u001b[34m[04/25/2022 13:41:08 INFO 140532052252480] Replicating 1415 random sentences from bucket (1, 1) to size it to multiple of 2048\u001b[0m\n",
      "\u001b[34m[04/25/2022 13:41:08 INFO 140532052252480] Parameters of encoders: [{'network': 'pooled_embedding', 'token_embedding_dim': '300', 'layers': 'auto', 'cnn_filter_width': '3', 'pretrained_embedding_file': '', 'freeze_pretrained_embedding': 'true', 'vocab_file': '', 'max_seq_len': '1', 'vocab_size': '611'}, {'network': 'pooled_embedding', 'token_embedding_dim': '300', 'layers': 'auto', 'cnn_filter_width': '3', 'pretrained_embedding_file': '', 'freeze_pretrained_embedding': 'true', 'vocab_file': '', 'max_seq_len': '1', 'vocab_size': '193610'}]\u001b[0m\n",
      "\u001b[34m[04/25/2022 13:41:08 INFO 140532052252480] Inconsistent enc_dim and token_embedding_dim found for token-embedding-encoder: 2048 vs 300. Setting token embedding dim to be 2048\u001b[0m\n",
      "\u001b[34m[04/25/2022 13:41:08 INFO 140532052252480] Inconsistent enc_dim and token_embedding_dim found for token-embedding-encoder: 2048 vs 300. Setting token embedding dim to be 2048\u001b[0m\n",
      "\u001b[34m[04/25/2022 13:41:08 INFO 140532052252480] Encoder configs: [{'num_layers': 1, 'enc_index': 0, 'token_embedding_dim': 2048, 'vocab_size': 611, 'vocab_file': '', 'vocab_dict': None, 'dropout': 0.0, 'pretrained_embedding_file': '', 'pretrained_embedding_file_path': None, 'freeze_pretrained_embedding': True, 'is_train': True}, {'num_layers': 1, 'enc_index': 1, 'token_embedding_dim': 2048, 'vocab_size': 193610, 'vocab_file': '', 'vocab_dict': None, 'dropout': 0.0, 'pretrained_embedding_file': '', 'pretrained_embedding_file_path': None, 'freeze_pretrained_embedding': True, 'is_train': True}]\u001b[0m\n",
      "\u001b[34m[04/25/2022 13:41:08 INFO 140532052252480] Config: {'enc_dim': 2048, 'max_seq_lens': [1, 1], 'dropout': 0.0, 'weight_decay': 0.0, 'mlp_activation': 'relu', 'mlp_dim': 1024, 'mlp_layers': 1, 'output_layer': 'softmax', 'learning_rate': 0.001, 'optimizer': 'adam', 'num_classes': 2, 'epochs': 20, 'mini_batch_size': 2048, 'bucket_width': 0, 'comparator_list': ['hadamard', 'concat', 'abs_diff'], 'tied_token_embedding_weight': False, 'negative_sampling_rate': 0, 'token_embedding_storage_type': 'dense', 'early_stopping_patience': 3, 'early_stopping_tolerance': 0.01, 'enc_configs': [{'num_layers': 1, 'enc_index': 0, 'token_embedding_dim': 2048, 'vocab_size': 611, 'vocab_file': '', 'vocab_dict': None, 'dropout': 0.0, 'pretrained_embedding_file': '', 'pretrained_embedding_file_path': None, 'freeze_pretrained_embedding': True, 'is_train': True}, {'num_layers': 1, 'enc_index': 1, 'token_embedding_dim': 2048, 'vocab_size': 193610, 'vocab_file': '', 'vocab_dict': None, 'dropout': 0.0, 'pretrained_embedding_file': '', 'pretrained_embedding_file_path': None, 'freeze_pretrained_embedding': True, 'is_train': True}]}\u001b[0m\n",
      "\u001b[34m[04/25/2022 13:41:08 INFO 140532052252480] Creating new state\u001b[0m\n",
      "\u001b[34m[04/25/2022 13:41:08 INFO 140532052252480] params {'enc_dim': '2048', 'mlp_dim': '1024', 'mlp_activation': 'relu', 'mlp_layers': '1', 'output_layer': 'softmax', 'optimizer': 'adam', 'learning_rate': '0.001', 'mini_batch_size': '2048', 'epochs': '20', 'bucket_width': '0', 'early_stopping_tolerance': '0.01', 'early_stopping_patience': '3', 'dropout': 0, 'weight_decay': 0, 'negative_sampling_rate': 0, 'comparator_list': 'hadamard, concat, abs_diff', 'tied_token_embedding_weight': 'false', 'token_embedding_storage_type': 'dense', 'enc0_network': 'pooled_embedding', 'enc1_network': 'pooled_embedding', 'enc0_token_embedding_dim': '300', 'enc0_layers': 'auto', 'enc0_cnn_filter_width': '3', 'enc1_token_embedding_dim': '300', 'enc1_layers': 'auto', 'enc1_cnn_filter_width': '3', 'enc0_pretrained_embedding_file': '', 'enc0_freeze_pretrained_embedding': 'true', 'enc1_pretrained_embedding_file': '', 'enc1_freeze_pretrained_embedding': 'true', 'enc0_vocab_file': '', 'enc1_vocab_file': '', 'num_classes': '2', '_num_gpus': 'auto', '_num_kv_servers': 'auto', '_tuning_objective_metric': '', '_kvstore': 'device', 'enc0_max_seq_len': '1', 'enc0_vocab_size': '611', 'enc1_max_seq_len': '1', 'enc1_vocab_size': '193610', 'default_bucket_key': (1, 1)}\u001b[0m\n",
      "\u001b[34m[04/25/2022 13:41:08 INFO 140532052252480] default_bucket_key (1, 1)\u001b[0m\n",
      "\u001b[34m[04/25/2022 13:41:08 INFO 140532052252480] nvidia-smi: took 0.032 seconds to run.\u001b[0m\n",
      "\u001b[34m[04/25/2022 13:41:08 INFO 140532052252480] nvidia-smi identified 0 GPUs.\u001b[0m\n",
      "\u001b[34m[04/25/2022 13:41:08 INFO 140532052252480] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[04/25/2022 13:41:08 INFO 140532052252480] context [cpu(0)]\u001b[0m\n",
      "\u001b[34m[04/25/2022 13:41:08 INFO 140532052252480] Create Store: device\u001b[0m\n",
      "\u001b[34m[04/25/2022 13:41:08 INFO 140532052252480] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[04/25/2022 13:41:08 WARNING 140532052252480] dense token embedding is used in a multi-gpu setting...consider changing 'token_embedding_storage_type' to 'row_sparse'\u001b[0m\n",
      "\u001b[34m[04/25/2022 13:41:08 INFO 140532052252480] data_names: ['source', 'target']\u001b[0m\n",
      "\u001b[34m[04/25/2022 13:41:08 INFO 140532052252480] label_names: ['out_layer_label']\u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mLayer (type)                                        Output Shape            Param #     Previous Layer                  \u001b[0m\n",
      "\u001b[34m========================================================================================================================\u001b[0m\n",
      "\u001b[34msource(null)                                        1                       0                                           \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34membed_0(Embedding)                                  1x2048                  0           source                          \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34m_not_equal_scalar0(_not_equal_scalar)               1                       0           source                          \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mreshape0(Reshape)                                   1x1                     0           _not_equal_scalar0              \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mbroadcast_mul0(broadcast_mul)                       1x2048                  0           embed_0                         \n",
      "                                                                                        reshape0                        \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34msum0(sum)                                           2048                    0           broadcast_mul0                  \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34msum1(sum)                                           1                       0           reshape0                        \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mzeros_like0(zeros_like)                             1                       0           sum1                            \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34m_equal0(_equal)                                     1                       0           sum1                            \n",
      "                                                                                        zeros_like0                     \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34m_plus0(elemwise_add)                                1                       0           sum1                            \n",
      "                                                                                        _equal0                         \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mbroadcast_div0(broadcast_div)                       2048                    0           sum0                            \n",
      "                                                                                        _plus0                          \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mdropout0(Dropout)                                   2048                    0           broadcast_div0                  \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34membed_1(Embedding)                                  1x2048                  0                                           \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34m_not_equal_scalar1(_not_equal_scalar)               1                       0                                           \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mreshape1(Reshape)                                   1x1                     0           _not_equal_scalar1              \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mbroadcast_mul1(broadcast_mul)                       1x2048                  0           embed_1                         \n",
      "                                                                                        reshape1                        \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34msum2(sum)                                           2048                    0           broadcast_mul1                  \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34msum3(sum)                                           1                       0           reshape1                        \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mzeros_like1(zeros_like)                             1                       0           sum3                            \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34m_equal1(_equal)                                     1                       0           sum3                            \n",
      "                                                                                        zeros_like1                     \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34m_plus1(elemwise_add)                                1                       0           sum3                            \n",
      "                                                                                        _equal1                         \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mbroadcast_div1(broadcast_div)                       2048                    0           sum2                            \n",
      "                                                                                        _plus1                          \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mdropout1(Dropout)                                   2048                    0           broadcast_div1                  \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34m_mul0(elemwise_mul)                                 2048                    0           dropout0                        \n",
      "                                                                                        dropout1                        \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34m_minus0(elemwise_sub)                               2048                    0           dropout0                        \n",
      "                                                                                        dropout1                        \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mabs0(abs)                                           2048                    0           _minus0                         \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mconcat0(Concat)                                     8192                    0           _mul0                           \n",
      "                                                                                        dropout0                        \n",
      "                                                                                        dropout1                        \n",
      "                                                                                        abs0                            \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mmlp_fc0(FullyConnected)                             1024                    8389632     concat0                         \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mactivation0(Activation)                             1024                    0           mlp_fc0                         \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mdropout2(Dropout)                                   1024                    0           activation0                     \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34moutput_layer(FullyConnected)                        2                       2050        dropout2                        \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mout_layer(SoftmaxOutput)                            2                       0           output_layer                    \u001b[0m\n",
      "\u001b[34m========================================================================================================================\u001b[0m\n",
      "\u001b[34mTotal params: 8391682\u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34m[04/25/2022 13:41:08 INFO 140532052252480] data_shapes [DataDesc[source,(2048, 1),<class 'numpy.float32'>,NTC], DataDesc[target,(2048, 1),<class 'numpy.float32'>,NTC]]\u001b[0m\n",
      "\u001b[34m[04/25/2022 13:41:08 INFO 140532052252480] label_shapes [DataDesc[out_layer_label,(2048,),<class 'numpy.float32'>,NTC]]\u001b[0m\n",
      "\u001b[34m[04/25/2022 13:41:08 INFO 140532052252480] fixed_param_names: []\u001b[0m\n",
      "\u001b[34m[04/25/2022 13:41:08 INFO 140532052252480] Initialized BucketingPlus Module\u001b[0m\n",
      "\u001b[34m[04/25/2022 13:41:08 INFO 140532052252480] arg_params keys for module initialization: dict_keys([])\u001b[0m\n",
      "\u001b[34m[04/25/2022 13:41:08 INFO 140532052252480] all params:dict_keys(['embed_0_weight', 'embed_1_weight', 'mlp_fc0_weight', 'mlp_fc0_bias', 'output_layer_weight', 'output_layer_bias'])\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1650894065.836219, \"EndTime\": 1650894068.396814, \"Dimensions\": {\"Algorithm\": \"ObjectToVec\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"initialize.time\": {\"sum\": 59.63325500488281, \"count\": 1, \"min\": 59.63325500488281, \"max\": 59.63325500488281}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1650894068.3969758, \"EndTime\": 1650894068.3970304, \"Dimensions\": {\"Algorithm\": \"ObjectToVec\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"Meta\": \"init_train_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Total Batches Seen\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Max Records Seen Between Resets\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Max Batches Seen Between Resets\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Reset Count\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Number of Records Since Last Reset\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Number of Batches Since Last Reset\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2022-04-25 13:41:17 Training - Training image download completed. Training in progress.\u001b[34m[04/25/2022 13:41:56 INFO 140532052252480] **************\u001b[0m\n",
      "\u001b[34m[04/25/2022 13:41:56 INFO 140532052252480] Completed Epoch: 0, time taken: 0:00:47.340911\u001b[0m\n",
      "\u001b[34m[04/25/2022 13:41:56 INFO 140532052252480] Epoch 0 Training metrics:   perplexity: 1.785 cross_entropy: 0.580 accuracy: 0.696 \u001b[0m\n",
      "\u001b[34m[04/25/2022 13:41:56 INFO 140532052252480] #quality_metric: host=algo-1, epoch=0, train cross_entropy <loss>=0.579517438605025\u001b[0m\n",
      "\u001b[34m[04/25/2022 13:41:56 INFO 140532052252480] #quality_metric: host=algo-1, epoch=0, train accuracy <score>=0.6962758657094594\u001b[0m\n",
      "\u001b[34m[04/25/2022 13:41:58 INFO 140532052252480] Epoch 0 Validation metrics: perplexity: 1.715 cross_entropy: 0.539 accuracy: 0.728 \u001b[0m\n",
      "\u001b[34m[04/25/2022 13:41:58 INFO 140532052252480] #quality_metric: host=algo-1, epoch=0, validation cross_entropy <loss>=0.5392816800337571\u001b[0m\n",
      "\u001b[34m[04/25/2022 13:41:58 INFO 140532052252480] #quality_metric: host=algo-1, epoch=0, validation accuracy <score>=0.7283653846153846\u001b[0m\n",
      "\u001b[34m[04/25/2022 13:41:58 INFO 140532052252480] **************\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1650894068.3969243, \"EndTime\": 1650894118.9602475, \"Dimensions\": {\"Algorithm\": \"ObjectToVec\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"epochs\": {\"sum\": 20.0, \"count\": 1, \"min\": 20, \"max\": 20}, \"early_stop.time\": {\"sum\": 0.2999305725097656, \"count\": 1, \"min\": 0.2999305725097656, \"max\": 0.2999305725097656}, \"update.time\": {\"sum\": 49403.40566635132, \"count\": 1, \"min\": 49403.40566635132, \"max\": 49403.40566635132}}}\u001b[0m\n",
      "\u001b[34m[04/25/2022 13:41:58 INFO 140532052252480] #progress_metric: host=algo-1, completed 5.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1650894069.5568216, \"EndTime\": 1650894118.9604878, \"Dimensions\": {\"Algorithm\": \"ObjectToVec\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 75776.0, \"count\": 1, \"min\": 75776, \"max\": 75776}, \"Total Batches Seen\": {\"sum\": 37.0, \"count\": 1, \"min\": 37, \"max\": 37}, \"Max Records Seen Between Resets\": {\"sum\": 75776.0, \"count\": 1, \"min\": 75776, \"max\": 75776}, \"Max Batches Seen Between Resets\": {\"sum\": 37.0, \"count\": 1, \"min\": 37, \"max\": 37}, \"Reset Count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}, \"Number of Records Since Last Reset\": {\"sum\": 75776.0, \"count\": 1, \"min\": 75776, \"max\": 75776}, \"Number of Batches Since Last Reset\": {\"sum\": 37.0, \"count\": 1, \"min\": 37, \"max\": 37}}}\u001b[0m\n",
      "\u001b[34m[04/25/2022 13:41:58 INFO 140532052252480] #throughput_metric: host=algo-1, train throughput=1533.8095987822164 records/second\u001b[0m\n",
      "\u001b[34m[04/25/2022 13:42:47 INFO 140532052252480] **************\u001b[0m\n",
      "\u001b[34m[04/25/2022 13:42:47 INFO 140532052252480] Completed Epoch: 1, time taken: 0:00:43.226595\u001b[0m\n",
      "\u001b[34m[04/25/2022 13:42:47 INFO 140532052252480] Epoch 1 Training metrics:   perplexity: 1.615 cross_entropy: 0.480 accuracy: 0.769 \u001b[0m\n",
      "\u001b[34m[04/25/2022 13:42:47 INFO 140532052252480] #quality_metric: host=algo-1, epoch=1, train cross_entropy <loss>=0.47964312337540294\u001b[0m\n",
      "\u001b[34m[04/25/2022 13:42:47 INFO 140532052252480] #quality_metric: host=algo-1, epoch=1, train accuracy <score>=0.7687526393581081\u001b[0m\n",
      "\u001b[34m[04/25/2022 13:42:49 INFO 140532052252480] Epoch 1 Validation metrics: perplexity: 1.710 cross_entropy: 0.536 accuracy: 0.729 \u001b[0m\n",
      "\u001b[34m[04/25/2022 13:42:49 INFO 140532052252480] #quality_metric: host=algo-1, epoch=1, validation cross_entropy <loss>=0.5363490168864911\u001b[0m\n",
      "\u001b[34m[04/25/2022 13:42:49 INFO 140532052252480] #quality_metric: host=algo-1, epoch=1, validation accuracy <score>=0.7291165865384616\u001b[0m\n",
      "\u001b[34m[04/25/2022 13:42:49 INFO 140532052252480] **************\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1650894118.9603307, \"EndTime\": 1650894169.8328528, \"Dimensions\": {\"Algorithm\": \"ObjectToVec\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"early_stop.time\": {\"sum\": 48.553466796875, \"count\": 1, \"min\": 48.553466796875, \"max\": 48.553466796875}, \"update.time\": {\"sum\": 45356.15563392639, \"count\": 1, \"min\": 45356.15563392639, \"max\": 45356.15563392639}}}\u001b[0m\n",
      "\u001b[34m[04/25/2022 13:42:49 INFO 140532052252480] #progress_metric: host=algo-1, completed 10.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1650894124.4766824, \"EndTime\": 1650894169.8331213, \"Dimensions\": {\"Algorithm\": \"ObjectToVec\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 151552.0, \"count\": 1, \"min\": 151552, \"max\": 151552}, \"Total Batches Seen\": {\"sum\": 74.0, \"count\": 1, \"min\": 74, \"max\": 74}, \"Max Records Seen Between Resets\": {\"sum\": 75776.0, \"count\": 1, \"min\": 75776, \"max\": 75776}, \"Max Batches Seen Between Resets\": {\"sum\": 37.0, \"count\": 1, \"min\": 37, \"max\": 37}, \"Reset Count\": {\"sum\": 2.0, \"count\": 1, \"min\": 2, \"max\": 2}, \"Number of Records Since Last Reset\": {\"sum\": 75776.0, \"count\": 1, \"min\": 75776, \"max\": 75776}, \"Number of Batches Since Last Reset\": {\"sum\": 37.0, \"count\": 1, \"min\": 37, \"max\": 37}}}\u001b[0m\n",
      "\u001b[34m[04/25/2022 13:42:49 INFO 140532052252480] #throughput_metric: host=algo-1, train throughput=1670.674227993002 records/second\u001b[0m\n",
      "\u001b[34m[04/25/2022 13:43:37 INFO 140532052252480] **************\u001b[0m\n",
      "\u001b[34m[04/25/2022 13:43:37 INFO 140532052252480] Completed Epoch: 2, time taken: 0:00:42.954639\u001b[0m\n",
      "\u001b[34m[04/25/2022 13:43:37 INFO 140532052252480] Epoch 2 Training metrics:   perplexity: 1.502 cross_entropy: 0.407 accuracy: 0.811 \u001b[0m\n",
      "\u001b[34m[04/25/2022 13:43:37 INFO 140532052252480] #quality_metric: host=algo-1, epoch=2, train cross_entropy <loss>=0.40690231001054916\u001b[0m\n",
      "\u001b[34m[04/25/2022 13:43:37 INFO 140532052252480] #quality_metric: host=algo-1, epoch=2, train accuracy <score>=0.8113914695945946\u001b[0m\n",
      "\u001b[34m[04/25/2022 13:43:39 INFO 140532052252480] Epoch 2 Validation metrics: perplexity: 1.757 cross_entropy: 0.564 accuracy: 0.726 \u001b[0m\n",
      "\u001b[34m[04/25/2022 13:43:39 INFO 140532052252480] #quality_metric: host=algo-1, epoch=2, validation cross_entropy <loss>=0.56376130764301\u001b[0m\n",
      "\u001b[34m[04/25/2022 13:43:39 INFO 140532052252480] #quality_metric: host=algo-1, epoch=2, validation accuracy <score>=0.7259990985576923\u001b[0m\n",
      "\u001b[34m[04/25/2022 13:43:39 INFO 140532052252480] **************\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1650894169.8329365, \"EndTime\": 1650894219.1439269, \"Dimensions\": {\"Algorithm\": \"ObjectToVec\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"early_stop.time\": {\"sum\": 0.020742416381835938, \"count\": 1, \"min\": 0.020742416381835938, \"max\": 0.020742416381835938}, \"update.time\": {\"sum\": 44979.87866401672, \"count\": 1, \"min\": 44979.87866401672, \"max\": 44979.87866401672}}}\u001b[0m\n",
      "\u001b[34m[04/25/2022 13:43:39 INFO 140532052252480] #progress_metric: host=algo-1, completed 15.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1650894174.164033, \"EndTime\": 1650894219.144111, \"Dimensions\": {\"Algorithm\": \"ObjectToVec\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 227328.0, \"count\": 1, \"min\": 227328, \"max\": 227328}, \"Total Batches Seen\": {\"sum\": 111.0, \"count\": 1, \"min\": 111, \"max\": 111}, \"Max Records Seen Between Resets\": {\"sum\": 75776.0, \"count\": 1, \"min\": 75776, \"max\": 75776}, \"Max Batches Seen Between Resets\": {\"sum\": 37.0, \"count\": 1, \"min\": 37, \"max\": 37}, \"Reset Count\": {\"sum\": 3.0, \"count\": 1, \"min\": 3, \"max\": 3}, \"Number of Records Since Last Reset\": {\"sum\": 75776.0, \"count\": 1, \"min\": 75776, \"max\": 75776}, \"Number of Batches Since Last Reset\": {\"sum\": 37.0, \"count\": 1, \"min\": 37, \"max\": 37}}}\u001b[0m\n",
      "\u001b[34m[04/25/2022 13:43:39 INFO 140532052252480] #throughput_metric: host=algo-1, train throughput=1684.6526687252417 records/second\u001b[0m\n",
      "\u001b[34m[04/25/2022 13:44:23 INFO 140532052252480] **************\u001b[0m\n",
      "\u001b[34m[04/25/2022 13:44:23 INFO 140532052252480] Completed Epoch: 3, time taken: 0:00:44.536493\u001b[0m\n",
      "\u001b[34m[04/25/2022 13:44:23 INFO 140532052252480] Epoch 3 Training metrics:   perplexity: 1.180 cross_entropy: 0.165 accuracy: 0.942 \u001b[0m\n",
      "\u001b[34m[04/25/2022 13:44:23 INFO 140532052252480] #quality_metric: host=algo-1, epoch=3, train cross_entropy <loss>=0.16536098074268651\u001b[0m\n",
      "\u001b[34m[04/25/2022 13:44:23 INFO 140532052252480] #quality_metric: host=algo-1, epoch=3, train accuracy <score>=0.9424619932432432\u001b[0m\n",
      "\u001b[34m[04/25/2022 13:44:25 INFO 140532052252480] Epoch 3 Validation metrics: perplexity: 2.182 cross_entropy: 0.780 accuracy: 0.712 \u001b[0m\n",
      "\u001b[34m[04/25/2022 13:44:25 INFO 140532052252480] #quality_metric: host=algo-1, epoch=3, validation cross_entropy <loss>=0.7801618805298438\u001b[0m\n",
      "\u001b[34m[04/25/2022 13:44:25 INFO 140532052252480] #quality_metric: host=algo-1, epoch=3, validation accuracy <score>=0.7120267427884616\u001b[0m\n",
      "\u001b[34m[04/25/2022 13:44:25 INFO 140532052252480] **************\u001b[0m\n",
      "\u001b[34m[04/25/2022 13:44:25 INFO 140532052252480] patience losses: [0.5392816800337571, 0.5363490168864911, 0.56376130764301]\u001b[0m\n",
      "\u001b[34m[04/25/2022 13:44:25 INFO 140532052252480] min patience losses: 0.5363490168864911\u001b[0m\n",
      "\u001b[34m[04/25/2022 13:44:25 INFO 140532052252480] current loss: 0.7801618805298438\u001b[0m\n",
      "\u001b[34m[04/25/2022 13:44:25 INFO 140532052252480] absolute loss difference: 0.24381286364335275\u001b[0m\n",
      "\u001b[34m[04/25/2022 13:44:25 INFO 140532052252480] Bad epoch: loss has not improved (enough). Bad count:1\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1650894219.144003, \"EndTime\": 1650894265.637674, \"Dimensions\": {\"Algorithm\": \"ObjectToVec\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"early_stop.time\": {\"sum\": 0.23651123046875, \"count\": 1, \"min\": 0.23651123046875, \"max\": 0.23651123046875}, \"update.time\": {\"sum\": 46490.35096168518, \"count\": 1, \"min\": 46490.35096168518, \"max\": 46490.35096168518}}}\u001b[0m\n",
      "\u001b[34m[04/25/2022 13:44:25 INFO 140532052252480] #progress_metric: host=algo-1, completed 20.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1650894219.1473088, \"EndTime\": 1650894265.6378508, \"Dimensions\": {\"Algorithm\": \"ObjectToVec\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 303104.0, \"count\": 1, \"min\": 303104, \"max\": 303104}, \"Total Batches Seen\": {\"sum\": 148.0, \"count\": 1, \"min\": 148, \"max\": 148}, \"Max Records Seen Between Resets\": {\"sum\": 75776.0, \"count\": 1, \"min\": 75776, \"max\": 75776}, \"Max Batches Seen Between Resets\": {\"sum\": 37.0, \"count\": 1, \"min\": 37, \"max\": 37}, \"Reset Count\": {\"sum\": 4.0, \"count\": 1, \"min\": 4, \"max\": 4}, \"Number of Records Since Last Reset\": {\"sum\": 75776.0, \"count\": 1, \"min\": 75776, \"max\": 75776}, \"Number of Batches Since Last Reset\": {\"sum\": 37.0, \"count\": 1, \"min\": 37, \"max\": 37}}}\u001b[0m\n",
      "\u001b[34m[04/25/2022 13:44:25 INFO 140532052252480] #throughput_metric: host=algo-1, train throughput=1629.91960452002 records/second\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[04/25/2022 13:45:08 INFO 140532052252480] **************\u001b[0m\n",
      "\u001b[34m[04/25/2022 13:45:08 INFO 140532052252480] Completed Epoch: 4, time taken: 0:00:43.096698\u001b[0m\n",
      "\u001b[34m[04/25/2022 13:45:08 INFO 140532052252480] Epoch 4 Training metrics:   perplexity: 1.026 cross_entropy: 0.025 accuracy: 0.994 \u001b[0m\n",
      "\u001b[34m[04/25/2022 13:45:08 INFO 140532052252480] #quality_metric: host=algo-1, epoch=4, train cross_entropy <loss>=0.02542099356651306\u001b[0m\n",
      "\u001b[34m[04/25/2022 13:45:08 INFO 140532052252480] #quality_metric: host=algo-1, epoch=4, train accuracy <score>=0.9937447212837838\u001b[0m\n",
      "\u001b[34m[04/25/2022 13:45:11 INFO 140532052252480] Epoch 4 Validation metrics: perplexity: 2.504 cross_entropy: 0.918 accuracy: 0.719 \u001b[0m\n",
      "\u001b[34m[04/25/2022 13:45:11 INFO 140532052252480] #quality_metric: host=algo-1, epoch=4, validation cross_entropy <loss>=0.9177479468859159\u001b[0m\n",
      "\u001b[34m[04/25/2022 13:45:11 INFO 140532052252480] #quality_metric: host=algo-1, epoch=4, validation accuracy <score>=0.7186373197115384\u001b[0m\n",
      "\u001b[34m[04/25/2022 13:45:11 INFO 140532052252480] **************\u001b[0m\n",
      "\u001b[34m[04/25/2022 13:45:11 INFO 140532052252480] patience losses: [0.5363490168864911, 0.56376130764301, 0.7801618805298438]\u001b[0m\n",
      "\u001b[34m[04/25/2022 13:45:11 INFO 140532052252480] min patience losses: 0.5363490168864911\u001b[0m\n",
      "\u001b[34m[04/25/2022 13:45:11 INFO 140532052252480] current loss: 0.9177479468859159\u001b[0m\n",
      "\u001b[34m[04/25/2022 13:45:11 INFO 140532052252480] absolute loss difference: 0.3813989299994248\u001b[0m\n",
      "\u001b[34m[04/25/2022 13:45:11 INFO 140532052252480] Bad epoch: loss has not improved (enough). Bad count:2\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1650894265.6377437, \"EndTime\": 1650894311.0439951, \"Dimensions\": {\"Algorithm\": \"ObjectToVec\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"early_stop.time\": {\"sum\": 0.2346038818359375, \"count\": 1, \"min\": 0.2346038818359375, \"max\": 0.2346038818359375}, \"update.time\": {\"sum\": 45402.74930000305, \"count\": 1, \"min\": 45402.74930000305, \"max\": 45402.74930000305}}}\u001b[0m\n",
      "\u001b[34m[04/25/2022 13:45:11 INFO 140532052252480] #progress_metric: host=algo-1, completed 25.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1650894265.6412294, \"EndTime\": 1650894311.0441642, \"Dimensions\": {\"Algorithm\": \"ObjectToVec\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 378880.0, \"count\": 1, \"min\": 378880, \"max\": 378880}, \"Total Batches Seen\": {\"sum\": 185.0, \"count\": 1, \"min\": 185, \"max\": 185}, \"Max Records Seen Between Resets\": {\"sum\": 75776.0, \"count\": 1, \"min\": 75776, \"max\": 75776}, \"Max Batches Seen Between Resets\": {\"sum\": 37.0, \"count\": 1, \"min\": 37, \"max\": 37}, \"Reset Count\": {\"sum\": 5.0, \"count\": 1, \"min\": 5, \"max\": 5}, \"Number of Records Since Last Reset\": {\"sum\": 75776.0, \"count\": 1, \"min\": 75776, \"max\": 75776}, \"Number of Batches Since Last Reset\": {\"sum\": 37.0, \"count\": 1, \"min\": 37, \"max\": 37}}}\u001b[0m\n",
      "\u001b[34m[04/25/2022 13:45:11 INFO 140532052252480] #throughput_metric: host=algo-1, train throughput=1668.9634710301957 records/second\u001b[0m\n",
      "\u001b[34m[04/25/2022 13:45:53 INFO 140532052252480] **************\u001b[0m\n",
      "\u001b[34m[04/25/2022 13:45:53 INFO 140532052252480] Completed Epoch: 5, time taken: 0:00:42.889199\u001b[0m\n",
      "\u001b[34m[04/25/2022 13:45:53 INFO 140532052252480] Epoch 5 Training metrics:   perplexity: 1.005 cross_entropy: 0.005 accuracy: 0.999 \u001b[0m\n",
      "\u001b[34m[04/25/2022 13:45:53 INFO 140532052252480] #quality_metric: host=algo-1, epoch=5, train cross_entropy <loss>=0.0051082406079749\u001b[0m\n",
      "\u001b[34m[04/25/2022 13:45:53 INFO 140532052252480] #quality_metric: host=algo-1, epoch=5, train accuracy <score>=0.9994457347972973\u001b[0m\n",
      "\u001b[34m[04/25/2022 13:45:55 INFO 140532052252480] Epoch 5 Validation metrics: perplexity: 2.664 cross_entropy: 0.980 accuracy: 0.726 \u001b[0m\n",
      "\u001b[34m[04/25/2022 13:45:55 INFO 140532052252480] #quality_metric: host=algo-1, epoch=5, validation cross_entropy <loss>=0.9799349720661457\u001b[0m\n",
      "\u001b[34m[04/25/2022 13:45:55 INFO 140532052252480] #quality_metric: host=algo-1, epoch=5, validation accuracy <score>=0.7258864182692307\u001b[0m\n",
      "\u001b[34m[04/25/2022 13:45:55 INFO 140532052252480] **************\u001b[0m\n",
      "\u001b[34m[04/25/2022 13:45:55 INFO 140532052252480] patience losses: [0.56376130764301, 0.7801618805298438, 0.9177479468859159]\u001b[0m\n",
      "\u001b[34m[04/25/2022 13:45:55 INFO 140532052252480] min patience losses: 0.56376130764301\u001b[0m\n",
      "\u001b[34m[04/25/2022 13:45:55 INFO 140532052252480] current loss: 0.9799349720661457\u001b[0m\n",
      "\u001b[34m[04/25/2022 13:45:55 INFO 140532052252480] absolute loss difference: 0.41617366442313564\u001b[0m\n",
      "\u001b[34m[04/25/2022 13:45:55 INFO 140532052252480] Bad epoch: loss has not improved (enough). Bad count:3\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1650894311.044062, \"EndTime\": 1650894355.729536, \"Dimensions\": {\"Algorithm\": \"ObjectToVec\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"early_stop.time\": {\"sum\": 0.23412704467773438, \"count\": 1, \"min\": 0.23412704467773438, \"max\": 0.23412704467773438}, \"update.time\": {\"sum\": 44682.135820388794, \"count\": 1, \"min\": 44682.135820388794, \"max\": 44682.135820388794}}}\u001b[0m\n",
      "\u001b[34m[04/25/2022 13:45:55 INFO 140532052252480] #progress_metric: host=algo-1, completed 30.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1650894311.0473862, \"EndTime\": 1650894355.7297034, \"Dimensions\": {\"Algorithm\": \"ObjectToVec\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 454656.0, \"count\": 1, \"min\": 454656, \"max\": 454656}, \"Total Batches Seen\": {\"sum\": 222.0, \"count\": 1, \"min\": 222, \"max\": 222}, \"Max Records Seen Between Resets\": {\"sum\": 75776.0, \"count\": 1, \"min\": 75776, \"max\": 75776}, \"Max Batches Seen Between Resets\": {\"sum\": 37.0, \"count\": 1, \"min\": 37, \"max\": 37}, \"Reset Count\": {\"sum\": 6.0, \"count\": 1, \"min\": 6, \"max\": 6}, \"Number of Records Since Last Reset\": {\"sum\": 75776.0, \"count\": 1, \"min\": 75776, \"max\": 75776}, \"Number of Batches Since Last Reset\": {\"sum\": 37.0, \"count\": 1, \"min\": 37, \"max\": 37}}}\u001b[0m\n",
      "\u001b[34m[04/25/2022 13:45:55 INFO 140532052252480] #throughput_metric: host=algo-1, train throughput=1695.8797508105488 records/second\u001b[0m\n",
      "\u001b[34m[04/25/2022 13:46:38 INFO 140532052252480] **************\u001b[0m\n",
      "\u001b[34m[04/25/2022 13:46:38 INFO 140532052252480] Completed Epoch: 6, time taken: 0:00:43.165118\u001b[0m\n",
      "\u001b[34m[04/25/2022 13:46:38 INFO 140532052252480] Epoch 6 Training metrics:   perplexity: 1.001 cross_entropy: 0.001 accuracy: 1.000 \u001b[0m\n",
      "\u001b[34m[04/25/2022 13:46:38 INFO 140532052252480] #quality_metric: host=algo-1, epoch=6, train cross_entropy <loss>=0.0012916680205160298\u001b[0m\n",
      "\u001b[34m[04/25/2022 13:46:38 INFO 140532052252480] #quality_metric: host=algo-1, epoch=6, train accuracy <score>=0.9999868032094594\u001b[0m\n",
      "\u001b[34m[04/25/2022 13:46:41 INFO 140532052252480] Epoch 6 Validation metrics: perplexity: 2.905 cross_entropy: 1.066 accuracy: 0.731 \u001b[0m\n",
      "\u001b[34m[04/25/2022 13:46:41 INFO 140532052252480] #quality_metric: host=algo-1, epoch=6, validation cross_entropy <loss>=1.066479320709522\u001b[0m\n",
      "\u001b[34m[04/25/2022 13:46:41 INFO 140532052252480] #quality_metric: host=algo-1, epoch=6, validation accuracy <score>=0.7311823918269231\u001b[0m\n",
      "\u001b[34m[04/25/2022 13:46:41 INFO 140532052252480] **************\u001b[0m\n",
      "\u001b[34m[04/25/2022 13:46:41 INFO 140532052252480] patience losses: [0.7801618805298438, 0.9177479468859159, 0.9799349720661457]\u001b[0m\n",
      "\u001b[34m[04/25/2022 13:46:41 INFO 140532052252480] min patience losses: 0.7801618805298438\u001b[0m\n",
      "\u001b[34m[04/25/2022 13:46:41 INFO 140532052252480] current loss: 1.066479320709522\u001b[0m\n",
      "\u001b[34m[04/25/2022 13:46:41 INFO 140532052252480] absolute loss difference: 0.2863174401796782\u001b[0m\n",
      "\u001b[34m[04/25/2022 13:46:41 INFO 140532052252480] Bad epoch: loss has not improved (enough). Bad count:4\u001b[0m\n",
      "\u001b[34m[04/25/2022 13:46:41 INFO 140532052252480] Bad epochs exceeded patience. Stopping training early!\u001b[0m\n",
      "\u001b[34m[04/25/2022 13:46:41 INFO 140532052252480] Early stopping criterion met! Stopping training at epoch: 6\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1650894355.729601, \"EndTime\": 1650894401.1311047, \"Dimensions\": {\"Algorithm\": \"ObjectToVec\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"early_stop.time\": {\"sum\": 0.3521442413330078, \"count\": 1, \"min\": 0.3521442413330078, \"max\": 0.3521442413330078}, \"update.time\": {\"sum\": 45398.15950393677, \"count\": 1, \"min\": 45398.15950393677, \"max\": 45398.15950393677}}}\u001b[0m\n",
      "\u001b[34m[04/25/2022 13:46:41 INFO 140532052252480] Early stop condition met. Stopping training.\u001b[0m\n",
      "\u001b[34m[04/25/2022 13:46:41 INFO 140532052252480] #progress_metric: host=algo-1, completed 100 % epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1650894355.7329323, \"EndTime\": 1650894401.1313677, \"Dimensions\": {\"Algorithm\": \"ObjectToVec\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 530432.0, \"count\": 1, \"min\": 530432, \"max\": 530432}, \"Total Batches Seen\": {\"sum\": 259.0, \"count\": 1, \"min\": 259, \"max\": 259}, \"Max Records Seen Between Resets\": {\"sum\": 75776.0, \"count\": 1, \"min\": 75776, \"max\": 75776}, \"Max Batches Seen Between Resets\": {\"sum\": 37.0, \"count\": 1, \"min\": 37, \"max\": 37}, \"Reset Count\": {\"sum\": 7.0, \"count\": 1, \"min\": 7, \"max\": 7}, \"Number of Records Since Last Reset\": {\"sum\": 75776.0, \"count\": 1, \"min\": 75776, \"max\": 75776}, \"Number of Batches Since Last Reset\": {\"sum\": 37.0, \"count\": 1, \"min\": 37, \"max\": 37}}}\u001b[0m\n",
      "\u001b[34m[04/25/2022 13:46:41 INFO 140532052252480] #throughput_metric: host=algo-1, train throughput=1669.1284695316667 records/second\u001b[0m\n",
      "\u001b[34m[04/25/2022 13:46:41 WARNING 140532052252480] wait_for_all_workers will not sync workers since the kv store is not running distributed\u001b[0m\n",
      "\u001b[34m[04/25/2022 13:46:41 INFO 140532052252480] Best model based on epoch 1. Best loss: 0.536\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1650894401.1311686, \"EndTime\": 1650894401.1323955, \"Dimensions\": {\"Algorithm\": \"ObjectToVec\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"finalize.time\": {\"sum\": 0.7905960083007812, \"count\": 1, \"min\": 0.7905960083007812, \"max\": 0.7905960083007812}}}\u001b[0m\n",
      "\u001b[34m[04/25/2022 13:46:41 INFO 140532052252480] Serializing model to /opt/ml/model/model_algo-1\u001b[0m\n",
      "\u001b[34m[04/25/2022 13:46:43 INFO 140532052252480] Saved checkpoint to \"/tmp/tmpfowczcq4/state-0001.params\"\u001b[0m\n",
      "\u001b[34m[04/25/2022 13:46:47 INFO 140532052252480] Test data is not provided.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1650894401.1324425, \"EndTime\": 1650894407.4376192, \"Dimensions\": {\"Algorithm\": \"ObjectToVec\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"model.serialize.time\": {\"sum\": 6084.186792373657, \"count\": 1, \"min\": 6084.186792373657, \"max\": 6084.186792373657}, \"setuptime\": {\"sum\": 8.762121200561523, \"count\": 1, \"min\": 8.762121200561523, \"max\": 8.762121200561523}, \"totaltime\": {\"sum\": 341625.49233436584, \"count\": 1, \"min\": 341625.49233436584, \"max\": 341625.49233436584}}}\u001b[0m\n",
      "\u001b[34m[04/25/2022 13:46:47 INFO 140532052252480 integration.py:636] worker closed\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2022-04-25 13:47:02 Uploading - Uploading generated training model\n",
      "2022-04-25 13:50:33 Completed - Training job completed\n",
      "Training seconds: 670\n",
      "Billable seconds: 670\n"
     ]
    }
   ],
   "source": [
    "## get estimator\n",
    "classifier = sagemaker.estimator.Estimator(\n",
    "    container,\n",
    "    role,\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.m5.4xlarge\",\n",
    "    output_path=output_path,\n",
    "    sagemaker_session=sess,\n",
    ")\n",
    "\n",
    "## set hyperparameters\n",
    "classifier.set_hyperparameters(**hyperparameters_c)\n",
    "\n",
    "## train, tune, and test the model\n",
    "classifier.fit(input_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ed8b0b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "from sagemaker.serializers import JSONSerializer\n",
    "from sagemaker.deserializers import JSONDeserializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f201e83b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------!"
     ]
    }
   ],
   "source": [
    "classification_model = classifier.create_model()\n",
    "\n",
    "predictor_2 = classification_model.deploy(\n",
    "    serializer=JSONSerializer(),\n",
    "    deserializer=JSONDeserializer(),\n",
    "    content_type=\"application/json\",\n",
    "    initial_instance_count=1,\n",
    "    instance_type=\"ml.m5.4xlarge\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7331bbfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_c_data, valid_c_label = data_list_to_inference_format(\n",
    "    copy.deepcopy(validation_data_list), label_thres=3, binarize=True\n",
    ")\n",
    "predictions = predictor_2.predict(valid_c_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "592ef3e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy on the binarized validation set is 0.729\n"
     ]
    }
   ],
   "source": [
    "def get_class_accuracy(res, labels, thres):\n",
    "    if type(res) is dict:\n",
    "        res = res[\"predictions\"]\n",
    "    assert len(res) == len(labels), \"result and label length mismatch!\"\n",
    "    accuracy = 0\n",
    "    for row, label in zip(res, labels):\n",
    "        if type(row) is dict:\n",
    "            if row[\"scores\"][1] > thres:\n",
    "                prediction = 1\n",
    "            else:\n",
    "                prediction = 0\n",
    "            if label > thres:\n",
    "                label = 1\n",
    "            else:\n",
    "                label = 0\n",
    "            accuracy += 1 - (prediction - label) ** 2\n",
    "    return accuracy / float(len(res))\n",
    "\n",
    "\n",
    "print(\n",
    "    \"The accuracy on the binarized validation set is %.3f\"\n",
    "    % get_class_accuracy(predictions, valid_c_label, 0.5)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d43ffad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_movie_embedding_dict(movie_ids, trained_model):\n",
    "    input_instances = list()\n",
    "    for s_id in movie_ids:\n",
    "        input_instances.append({\"in1\": [s_id]})\n",
    "    data = {\"instances\": input_instances}\n",
    "    movie_embeddings = trained_model.predict(data)\n",
    "    embedding_dict = {}\n",
    "    for s_id, row in zip(movie_ids, movie_embeddings[\"predictions\"]):\n",
    "        embedding_dict[s_id] = np.array(row[\"embeddings\"])\n",
    "    return embedding_dict\n",
    "\n",
    "\n",
    "def load_movie_id_name_map(item_file):\n",
    "    movieID_name_map = {}\n",
    "    with open(item_file, \"r\", encoding=\"ISO-8859-1\") as f:\n",
    "        next(f)\n",
    "        for row in f.readlines():\n",
    "            row = row.strip()\n",
    "            split = row.split(\",\")\n",
    "            movie_id = split[0]\n",
    "            movie_name = split[1]\n",
    "            #sparse_tags = split[-19:]\n",
    "            movieID_name_map[int(movie_id)] = movie_name\n",
    "    return movieID_name_map\n",
    "\n",
    "\n",
    "def get_nn_of_movie(movie_id, candidate_movie_ids, embedding_dict):\n",
    "    movie_emb = embedding_dict[movie_id]\n",
    "    min_dist = float(\"Inf\")\n",
    "    best_id = candidate_movie_ids[0]\n",
    "    for idx, m_id in enumerate(candidate_movie_ids):\n",
    "        candidate_emb = embedding_dict[m_id]\n",
    "        curr_dist = np.linalg.norm(candidate_emb - movie_emb)\n",
    "        if curr_dist < min_dist:\n",
    "            best_id = m_id\n",
    "            min_dist = curr_dist\n",
    "    return best_id, min_dist\n",
    "\n",
    "\n",
    "def get_unique_movie_ids(data_list):\n",
    "    unique_movie_ids = set()\n",
    "    for row in data_list:\n",
    "        unique_movie_ids.add(row[\"in1\"][0])\n",
    "    return list(unique_movie_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "321e7882",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_list = load_csv_data(train_path, \",\", verbose=False)\n",
    "unique_movie_ids = get_unique_movie_ids(train_data_list)\n",
    "embedding_dict = get_movie_embedding_dict(unique_movie_ids, predictor_2)\n",
    "candidate_movie_ids = unique_movie_ids.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "147a20e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_id_to_examine = 195 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "78a0ffbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The closest movie to Something to Talk About (1995) in the embedding space is Loaded Weapon 1 (National Lampoon's Loaded Weapon 1) (1993)\n"
     ]
    }
   ],
   "source": [
    "candidate_movie_ids.remove(movie_id_to_examine)\n",
    "best_id, min_dist = get_nn_of_movie(movie_id_to_examine, candidate_movie_ids, embedding_dict)\n",
    "movieID_name_map = load_movie_id_name_map(\"ml-latest-small/movies.csv\")\n",
    "print(\n",
    "    \"The closest movie to {} in the embedding space is {}\".format(\n",
    "        movieID_name_map[movie_id_to_examine], movieID_name_map[best_id]\n",
    "    )\n",
    ")\n",
    "candidate_movie_ids.append(movie_id_to_examine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "46f8ecf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor_2.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e219efb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
